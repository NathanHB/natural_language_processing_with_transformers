{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cc56e0-2a77-4dd0-ba8d-3f3c787dcd41",
   "metadata": {},
   "source": [
    "# Named entity recognition using hugging face transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613402bf-27d2-4895-8a95-ded9351fa245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names, load_dataset, DatasetDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18d22e2-4843-4673-a314-697d4cc19909",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728476b6-7712-47aa-8dd7-daf298113b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configs\n"
     ]
    }
   ],
   "source": [
    "print(f\"XTREME has {len(xtreme_subsets)} configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9de584-6470-4869-8eef-1c124578afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathanh/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.de to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd498e09e0e4e378217c2c352e88e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b94fbb5dca445038b7612e928c67e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.fr to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e79edf43e0e4ebd9a5b8caf43580249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.it to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccea860c1de54ee59115745e227eb103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.en to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3379641d9d094fd4b35aac5c6483e8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "langs = ['de', 'fr', 'it', 'en']\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (ds[split].shuffle(seed=42).select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358ffc5a-418f-4294-a745-781c25487ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(datasets.dataset_dict.DatasetDict,\n",
       "            {'de': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 12580\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 6290\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 6290\n",
       "                 })\n",
       "             }),\n",
       "             'fr': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 4580\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 2290\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 2290\n",
       "                 })\n",
       "             }),\n",
       "             'it': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 1680\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 840\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 840\n",
       "                 })\n",
       "             }),\n",
       "             'en': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 1180\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 590\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 590\n",
       "                 })\n",
       "             })})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ce8700-7494-43d3-b495-af780b33fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       de    fr    it    en\n",
       "nb  12580  4580  1680  1180"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({lang: panx_ch[lang]['train'].num_rows for lang in langs}, index=['nb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84bff7bf-683c-4694-99db-42c5724c3715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['Moteur', 'à', 'combustion', 'contrôlée']\n",
      "ner_tags: [3, 4, 4, 4]\n",
      "langs: ['fr', 'fr', 'fr', 'fr']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch['fr']['train'][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aa4fe19-a9a6-4896-a533-e4c09b928899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch['fr']['train'].features['ner_tags'].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9a8ba76-744d-42c2-8ee8-3429202faca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_name(batch):\n",
    "    return {'ner_tags_str': [tags.int2str(idx) for idx in batch['ner_tags']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05afa316-9593-4a31-a68e-e0b60b97f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-8ca829fa4c15f605.arrow\n",
      "Loading cached processed dataset at /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-255562993960ed82.arrow\n",
      "Loading cached processed dataset at /home/nathanh/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3d83b77c6f610abb.arrow\n"
     ]
    }
   ],
   "source": [
    "panx_fr = panx_ch['fr'].map(create_tag_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e3f4480-7909-4773-861a-a930a54457e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>Kaitlyn</td>\n",
       "      <td>Weaver</td>\n",
       "      <td>/</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Poje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langs</th>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags_str</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0       1   2       3      4\n",
       "tokens        Kaitlyn  Weaver   /  Andrew   Poje\n",
       "ner_tags            1       2   0       1      2\n",
       "langs              fr      fr  fr      fr     fr\n",
       "ner_tags_str    B-PER   I-PER   O   B-PER  I-PER"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_example = panx_fr['train'][13]\n",
    "pd.DataFrame.from_dict(fr_example, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f31c2ae-7a31-4c89-842d-e2ecc1f03734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1788</td>\n",
       "      <td>2017</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>911</td>\n",
       "      <td>979</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>898</td>\n",
       "      <td>977</td>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ORG   PER   LOC\n",
       "train       1788  2017  2292\n",
       "validation   911   979  1060\n",
       "test         898   977  1153"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freq = defaultdict(Counter)\n",
    "for split, dataset in panx_fr.items():\n",
    "    for row in dataset['ner_tags_str']:\n",
    "        for tag in row:\n",
    "            if tag.startswith('B'):\n",
    "                tag_type = tag.split('-')[1]\n",
    "                split2freq[split][tag_type] += 1\n",
    "                \n",
    "pd.DataFrame.from_dict(split2freq, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2377baf9-49e9-4172-a49e-12f2949b8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd19d5e5-2dc2-4ef9-8e98-7a2164e0ac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a3d6ce09344ca181cf761f15adb20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db12ded61d04a56bb86d3a54bc79b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372cb406ab114893980248f8f0c7e685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_model_name = 'bert-base-cased'\n",
    "xlmr_model_name = 'xlm-roberta-base'\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "205e3feb-de7d-4cce-9771-83be6f8e10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db4e8567-5413-401c-b63f-3a187fe802c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n",
      "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(bert_tokens)\n",
    "print(xlmr_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d147b491-563d-44b7-bdff-c1c3a904b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig, AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbb00eac-103a-44e5-b200-135285013f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        out = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
    "        \n",
    "        sequence_output = self.dropout(out[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "           \n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=out.hidden_states, attentions=out.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1181d4c2-486d-4558-9dd7-bb73fe3fef60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/nathanh/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-PER\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"B-ORG\",\n",
      "    \"4\": \"I-ORG\",\n",
      "    \"5\": \"B-LOC\",\n",
      "    \"6\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 5,\n",
      "    \"B-ORG\": 3,\n",
      "    \"B-PER\": 1,\n",
      "    \"I-LOC\": 6,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/nathanh/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/pytorch_model.bin\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
    "config = AutoConfig.from_pretrained(xlmr_model_name, num_label=tags.num_classes, id2label=index2tag, label2id=tag2index)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "xlmr_model = XLMRobertaForTokenClassification(config).from_pretrained(xlmr_model_name, config=config).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e807ff0c-90c3-47c1-a139-19441c60e5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 21763, 37456, 15555,  5161,     7,  2356,  5753,    38,     2]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors='pt')\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21103da4-874e-41af-8c16-0f7a1f15d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3016, -0.4930, -0.1571,  0.1551, -0.3833,  0.1424, -0.3648],\n",
      "         [ 0.3214, -0.1811, -0.3872, -0.0291, -0.4006, -0.0980, -0.4319],\n",
      "         [ 0.3293, -0.2091, -0.3532,  0.0386, -0.4592, -0.0502, -0.4717],\n",
      "         [ 0.3838, -0.2421, -0.3164, -0.0009, -0.4087, -0.0827, -0.4094],\n",
      "         [ 0.2560, -0.1341, -0.3766, -0.0526, -0.4245,  0.0114, -0.3914],\n",
      "         [ 0.3134, -0.1605, -0.4155, -0.0566, -0.4641, -0.1533, -0.5159],\n",
      "         [ 0.3028, -0.1859, -0.3448,  0.0395, -0.4935, -0.1182, -0.5869],\n",
      "         [ 0.3135, -0.1393, -0.4194,  0.0191, -0.3489, -0.0740, -0.5115],\n",
      "         [ 0.3769, -0.1611, -0.4065, -0.2036, -0.4586, -0.1060, -0.4659],\n",
      "         [ 0.3089, -0.5409, -0.1109,  0.2145, -0.2947,  0.1478, -0.3195]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = xlmr_model(input_ids.to(device)).logits\n",
    "print(output)\n",
    "preds = torch.argmax(output, dim=-1)\n",
    "preds = [tags.names[p] for p in preds[0].cpu().numpy()]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0ef3b73b-da32-4241-ab5e-5a1a8ae6cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    input_ids = tokens.input_ids.to(device)\n",
    "    output = model(input_ids)[0] #take first batch\n",
    "    preds = torch.argmax(output, dim=-1)\n",
    "    preds = [tags.names[p] for p in preds[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens.tokens(), preds], index=['tokens', 'preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d3fc610-7e47-4fb7-aa40-840bab0957b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4  5     6      7  8     9\n",
       "tokens  <s>  ▁Jack  ▁Spar  row  ▁love  s  ▁New  ▁York  !  </s>\n",
       "preds     O      O      O    O      O  O     O      O  O     O"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_text(text, tags, xlmr_model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d020c-edf8-4da4-8980-e5e4b8ada0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
